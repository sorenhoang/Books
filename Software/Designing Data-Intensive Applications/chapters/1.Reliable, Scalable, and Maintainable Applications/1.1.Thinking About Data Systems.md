# **Topic 1.1 — Thinking About Data Systems**

Modern applications are becoming more **data-intensive**, meaning their primary challenges involve storing, processing, and retrieving large amounts of data rather than just executing computation. Because of this shift, we must think beyond traditional databases and consider the entire ecosystem of systems that manage, transform, and deliver data.

Instead of treating each system separately — database, cache, queue, search engine — it's more accurate to think of them collectively as **data systems**. Each system specializes in handling a particular type of workload or performance requirement. The key skill is understanding how they interact and when to use each one.

---

### **Why We Need a Broader Perspective**

Historically, a single relational database was enough to serve most applications. But modern systems deal with:

* Millions of users
* Global traffic
* High availability requirements
* Real-time analytics
* Massive data ingestion

As a result, a single tool rarely satisfies all needs. Modern architectures commonly combine multiple specialized systems such as:

* A primary transactional database (PostgreSQL, MySQL)
* A cache for low latency reads (Redis, Memcached)
* A full-text search engine (Elasticsearch)
* A message broker or event bus (Kafka, RabbitMQ)
* A data warehouse or analytics engine (Spark, BigQuery, Snowflake)

These systems complement each other rather than replace one another.

---

### **Understanding Workloads**

Different applications require different access patterns. Some examples:

* Online stores require fast reads and writes for orders → OLTP workloads
* Search systems require filtering, fuzzy matching, relevance ranking → indexing and search engines
* BI dashboards require aggregated historical data → OLAP analytics systems
* IoT platforms require ingesting constant streams of data → streaming systems

No single system handles all these workloads well, which is why modern architectures are polyglot.

---

### **Growth Influences Design Choices**

Architectural decisions evolve with scale. A small application may begin with a single database, but as load increases, architecture evolves:

1. Single database
2. Add caching for high-read workloads
3. Add replication for read scaling and redundancy
4. Apply sharding or partitioning to scale writes
5. Introduce message brokers to decouple services
6. Add batch or stream processing for analytics or data transformation
7. Expand to multi-region replication for global availability

This progression reflects real-world scaling patterns seen at companies like Netflix, Meta, Uber, or LinkedIn.

---

### **Performance Dimensions to Consider**

When thinking about data systems, performance isn't a single metric. It involves:

* **Latency**: How quickly a single request is processed
* **Throughput**: How many requests the system can serve per second
* **Access patterns**: Random read/write, sequential writes, bulk analytics, or streaming ingestion
* **Consistency guarantees**: Strong, eventual, causal, session consistency, etc.
* **Failure tolerance**: How the system behaves when components fail

Different workloads require different trade-offs in these dimensions.

---

### **Real-World Mapping of System Types**

Data systems fall roughly into these categories:

* OLTP transactional storage (PostgreSQL, MySQL, MongoDB)
* Caching systems for fast lookups (Redis, Memcached)
* Search engines for unstructured or text-heavy querying (Elasticsearch, Solr)
* Event streaming and messaging (Kafka, Pulsar)
* Batch and analytics processing engines (Spark, Hadoop, BigQuery)
* Coordination systems for distributed services (Zookeeper, etcd, Consul)

Understanding *why* each exists is more important than memorizing features.

---

### **A Mindset of Trade-offs**

Thinking about data systems means designing based on constraints, not trends. Key questions include:

* Do we need strong consistency or can we tolerate eventual consistency?
* Is read throughput more important than write throughput?
* Can latency spikes be tolerated?
* Does the system need to scale horizontally or vertically?
* Who will operate this system — and how difficult will it be?

Every system introduces operational cost — complexity must be justified by real needs.

---

### **Key Takeaways of the Topic**

* "Database" is too narrow — modern systems use multiple data infrastructure components.
* Different workloads require different tools and architectural approaches.
* System decisions evolve with growth and change over time.
* Building data-intensive systems means balancing latency, throughput, reliability, scalability, and maintainability.
* The real challenge isn't choosing tools — it's integrating them into a coherent, dependable architecture.