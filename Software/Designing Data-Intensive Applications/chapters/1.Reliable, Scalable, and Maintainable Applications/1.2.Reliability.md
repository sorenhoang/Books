# **Topic 1.2 — Reliability**

A reliable system is one that continues to function correctly even when things go wrong. Reliability does not mean eliminating all failures — because hardware breaks, networks fluctuate, and software contains bugs. Instead, reliability is about designing systems that can **tolerate faults** and continue operating correctly despite them.

For a system to be considered reliable, it must do what users expect. If the system returns incorrect data, loses information, becomes unavailable at critical times, or behaves inconsistently, users perceive it as unreliable. Reliability is closely tied to trust: users trust a reliable system because it consistently delivers expected results.

---

### **Why Reliability Matters**

As systems scale and complexity increases, the probability of failure increases. A single machine might run smoothly, but when you operate hundreds or thousands of machines (common in distributed systems), failures become routine rather than exceptional events. At scale, hardware failure is normal, and software must handle it gracefully. For example, companies like Amazon or Google assume that at any given moment, multiple machines, disks, or network links are failing.

In addition, reliability matters because systems increasingly underpin critical services like financial transactions, healthcare, logistics, or communication platforms. The cost of failure can range from user frustration to legal, financial, or life-impacting consequences.

---

### **Common Threats to Reliability**

There are three broad categories of faults that systems must handle:

1. **Hardware Faults**

   * Disk failures, power outages, network interruptions, and machine crashes fall into this category.
   * These become more common as the number of machines increases.
   * Traditional response: redundancy, replication, backups, and failover mechanisms.

2. **Software Faults**

   * These include bugs, deadlocks, race conditions, memory leaks, and unexpected edge cases.
   * Software failures are often systematic and repeatable, unlike random hardware failures.
   * Preventing software failures often relies on testing, static analysis, fault injection, and defensive coding.

3. **Human Error**

   * Misconfiguration, incorrect deployment, or accidental data deletion are major causes of outages.
   * Humans cause system failures more often than hardware or even software flaws.
   * Systems must anticipate human mistakes with safeguards, rollbacks, staging environments, and clear operational tooling.

---

### **Approaches to Fault Tolerance**

Since failures are inevitable, systems must detect and recover from them automatically. Key strategies include:

* **Redundancy and replication:** Keeping multiple copies of data ensures the system continues operating even if individual components fail. Databases often use leader–follower replication or multi-leader designs to ensure durability and high availability.

* **Failover mechanisms:** Automated failover ensures another node, instance, or region takes over when a primary component fails. This requires careful coordination to avoid split-brain or inconsistent state.

* **Self-healing and recovery:** Some systems (like Kafka, Cassandra, Kubernetes) automatically rebalance or repair state after faults.

* **Durable storage:** Writing data to disk (and often multiple disks or machines) ensures persistence even after restarts or crashes.

Fault tolerance must balance speed, correctness, and user experience. For example, synchronous replication improves safety but increases latency, while asynchronous replication improves responsiveness but risks data loss.

---

### **Reliability and Correctness Guarantees**

A reliable system should protect against data loss, corruption, or inconsistent behavior. Guarantees commonly associated with reliability include:

* **Durability:** Once the system acknowledges a write, the data should not disappear—even after a crash.
* **Correctness:** The system should return accurate, expected results, not partial or corrupted data.
* **Availability:** The system should remain usable even during component failures.
* **Predictable behavior under load:** Performance degradation should be graceful, not catastrophic.

Ensuring these guarantees often involves trade-offs, especially in distributed environments. For example, the CAP theorem highlights the tension between consistency and availability under network partitions.

---

### **Mitigating Human Error**

Because humans are a primary source of failure, reliable systems invest heavily in reducing operational complexity:

* Safe defaults and guardrails (e.g., confirmation before deleting production data)
* Immutable infrastructure and reproducible deployments
* Progressive rollout and canary releases
* Observability (logging, metrics, tracing, alerting)
* Well-tested automation replacing manual procedures

Rather than expecting perfect operators, reliable systems assume mistakes will happen and provide mechanisms to recover quickly.

---

### **Testing Reliability**

Reliability is validated through real-world stress and chaos scenarios, not just unit tests. Techniques include:

* **Chaos testing:** Tools like Netflix’s Chaos Monkey randomly terminate components to ensure fault tolerance.
* **Load and soak testing:** Simulating prolonged heavy traffic reveals memory leaks and hidden bottlenecks.
* **Simulated failure drills:** Practicing recovery prepares teams and exposes operational weaknesses.

Systems must not only work during normal conditions — they must work when unexpected events occur.

---

### **Key Principles of Designing Reliable Systems**

* Failures must be **expected**, not treated as rare exceptions.
* Systems should be resilient through **redundancy, replication, and automation**.
* Human operations should be **supported by tooling**, not rely on memory or manual commands.
* Reliability requires a combination of **architecture, operational practices, and organizational habits**.
* The goal is not zero failures, but a system that **continues working even in the presence of faults**.

---

### **Core Idea**

Reliability is about ensuring the system behaves correctly and predictably even when components fail. It requires designing for failure, planning recovery mechanisms, reducing human risk, and providing strong guarantees around data correctness, availability, and durability. A reliable system is not one that never fails — but one that **keeps functioning despite failures**.