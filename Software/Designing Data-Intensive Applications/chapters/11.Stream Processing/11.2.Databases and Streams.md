# **Databases and Streams**

The connection between databases and streams runs deeper than just the physical storage of logs; it is fundamental to how data systems operate. A replication log is essentially a **stream of write events**, and **state machine replication** relies on every replica processing those events in the same order,.

### **Keeping Systems in Sync**

Most nontrivial applications must combine multiple technologies—such as an OLTP database, a cache, a full-text search index, and a data warehouse—to satisfy their requirements. Keeping these systems in sync is difficult.

* **Dual Writes:** A common but problematic approach is for the application to explicitly write to each system (e.g., update the database, then update the search index). This suffers from serious **race conditions** where concurrent writes can be processed in different orders by different systems, leading to permanent inconsistency,.
* **Fault Tolerance:** If one write succeeds and the other fails, the systems drift out of sync. Solving this typically requires expensive atomic commit protocols like 2PC.

### **Change Data Capture (CDC)**

**Change Data Capture** is the process of observing all data changes written to a database and extracting them into a stream that can be replicated to derived data systems (like search indexes or data warehouses).

* **Leader-Follower Relationship:** CDC effectively makes the database the leader and the derived systems the followers. Using a log-based message broker to transport these events ensures ordering is preserved.
* **Implementation:** While triggers can be used, they are often fragile. A more robust approach involves parsing the database's **replication log** (e.g., PostgreSQL WAL, MySQL binlog). Tools like Debezium, Maxwell, and Databus operate on this principle,.
* **Log Compaction:** To avoid keeping the entire history of changes, log compaction can be used. If updates replace previous values for a key, the log can discard old values, retaining only the most recent update. This allows the reconstruction of the entire database state from the log without requiring a snapshot,.

### **Event Sourcing**

While CDC extracts low-level state changes from a database, **Event Sourcing** is a technique from the Domain-Driven Design community that applies similar principles at the application level.

* **Intent vs. Side Effects:** CDC records the *effect* of an action (e.g., "record updated"). Event sourcing records the user's **intent** as an immutable event (e.g., "student cancelled course"). This stores "what happened" rather than the resulting state,.
* **Commands vs. Events:** A user request is initially a **command** (which can fail validation). Once accepted, it becomes an **event** (a persistent fact). Consumers cannot reject events; validation must occur before the event is written,.
* **Deriving State:** The event log itself is not useful for user queries (e.g., "what is my cart total?"). The system must derive the current application state by processing the log. Unlike CDC, log compaction is difficult here because new events typically do not strictly overwrite old ones; the full history is often needed,.

### **State, Streams, and Immutability**

Mutable state and append-only logs are two sides of the same coin: **application state is what you get when you integrate an event stream over time**.

* **The Truth is the Log:** From this perspective, the database is merely a cache of a subset of the log (the latest values). The log is the system of record.
* **Advantages of Immutability:** Immutable events offer better **auditability** (similar to financial ledgers) and help recovery from bugs. If bad code writes incorrect data to a mutable database, the data is lost. With an event log, you can fix the code and **reprocess** the events to correct the state,.
* **CQRS:** Separating the form in which data is written (event log) from the form in which it is read (database view) is known as **Command Query Responsibility Segregation**. This allows for highly denormalized read views that are optimized for specific queries, which are kept in sync via the event stream,.
* **Concurrency:** Event sourcing can simplify concurrency control. Since user actions are self-contained events appended to a log, atomic operations can often replace complex multi-object transactions. If the log and application state are partitioned the same way, a single-threaded consumer can process writes deterministically without concurrency issues,.
