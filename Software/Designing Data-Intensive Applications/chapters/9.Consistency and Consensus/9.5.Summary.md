# ðŸ“˜ **Chapter 9 â€” Consistency and Consensus**

## **High-Level Purpose of Chapter 9**

Chapter 9 explains **how distributed systems reach agreement (consensus)** and **what kinds of consistency guarantees are possible** in a world with:

* partial failures
* unreliable networks
* unreliable clocks
* incomplete knowledge

It builds directly on Chapter 8 and answers the question:

> *â€œGiven all this uncertainty, how can systems still behave correctly?â€*

---

# ðŸ§  **Core Ideas of Chapter 9**

## **1. Consistency Is a Spectrum, Not a Boolean**

Consistency is **not one thing**. Different systems provide different guarantees depending on trade-offs between:

* correctness
* availability
* latency
* scalability

There is **no universally â€œbestâ€ consistency model**.

---

## **2. Linearizability (Strong Consistency)**

### **Definition**

> An operation appears to take effect **atomically at a single point in time**, and **real-time ordering is preserved**.

If operation A completes before B starts, **everyone must see A before B**.

### **Properties**

* strongest single-object consistency model
* intuitive for developers
* easy to reason about

### **Cost**

* high latency
* reduced availability during partitions
* requires coordination (quorum, leader, consensus)

### **Used for**

* locks
* leader election
* unique IDs
* compare-and-set
* metadata systems

---

## **3. Eventual Consistency**

### **Definition**

> If no new updates are made, all replicas will **eventually converge** to the same value.

### **Properties**

* high availability
* low latency
* tolerant of partitions
* weak ordering guarantees

### **Challenges**

* stale reads
* conflicts
* divergent replicas

### **Conflict resolution**

* last-write-wins (dangerous)
* version vectors
* CRDTs
* application-level reconciliation

---

## **4. Causal Consistency (Middle Ground)**

### **Definition**

> If event A causally influenced event B, **everyone must see A before B**.

Does **not** require global ordering for unrelated events.

### **Benefits**

* stronger than eventual consistency
* weaker (cheaper) than linearizability
* intuitive for user-facing systems

### **Used in**

* social feeds
* messaging systems
* collaborative apps

---

## **5. Why Consensus Exists**

Consensus solves questions like:

* Who is the leader?
* Which value is committed?
* What is the current configuration?
* Which node owns this resource?

Consensus guarantees:

* **Safety**: no two nodes decide differently
* **Liveness**: system eventually makes progress (under assumptions)

---

## **6. Consensus Is Hard (and Expensive)**

Consensus must tolerate:

* message loss
* delays
* duplicate messages
* node crashes
* leadership changes

Key limitations:

* impossible to guarantee both safety and liveness under all conditions
* requires timeouts and retries
* performance cost is unavoidable

---

## **7. Leader-Based Consensus (Raft / Paxos)**

### **Key pattern**

* one leader at a time
* leader proposes values
* majority quorum required
* followers replicate log
* leader failure â†’ new election

### **Why leaders help**

* simplify ordering
* reduce conflicts
* improve performance

But:

* leader is a bottleneck
* failover adds latency

---

## **8. Epochs, Terms, and Fencing**

Because leaders can be wrong:

* each leadership has a **term/epoch**
* higher term always wins
* stale leaders are rejected

This prevents:

* zombie leaders
* split-brain
* stale writes

---

## **9. CAP Revisited (Correct Interpretation)**

CAP does **not** say:

> â€œPick two and forget the thirdâ€

It says:

> **During a network partition**, you must choose between:

* Consistency
* Availability

Partition tolerance is mandatory.

Most real systems:

* choose availability by default
* selectively add strong consistency where needed

---

## **10. Consistency vs Transactions**

* **Consistency models** â†’ what clients observe
* **Transactions** â†’ how multiple operations behave together

You can have:

* serializable transactions without linearizable reads
* linearizable reads without multi-object transactions

They solve **different problems**.

---

## **11. When to Use Strong Consistency**

Use **linearizability or consensus** when:

* correctness matters more than latency
* invariants must be enforced
* coordination is unavoidable

Examples:

* distributed locks
* leader election
* schema changes
* configuration management

---

## **12. When NOT to Use Strong Consistency**

Avoid strong consistency when:

* low latency is critical
* system must stay available during partitions
* operations are idempotent or commutative
* eventual convergence is acceptable

Examples:

* metrics
* logs
* feeds
* analytics
* caches

---

# ðŸ§© **Final Mental Model from Chapter 9**

> **Consistency is a choice, consensus is a tool, and uncertainty is unavoidable.**

Designers must:

* choose consistency per operation
* isolate strongly consistent components
* accept weaker guarantees elsewhere
* pay coordination cost only when necessary

---

# ðŸŽ¯ **Final Interview Questions â€” Chapter 9 (With Answers)**

---

## **1. What is linearizability and why is it expensive?**

**Answer:**
Linearizability guarantees that operations appear atomic and respect real-time order. It is expensive because it requires coordination, quorums, and often leader-based replication, which increases latency and reduces availability during partitions.

---

## **2. How is linearizability different from serializability?**

**Answer:**

* **Linearizability**: applies to single operations and respects real-time order.
* **Serializability**: applies to transactions and guarantees equivalence to some sequential execution, but not necessarily real-time order.

They solve different problems.

---

## **3. Why does CAP matter in practice?**

**Answer:**
Because network partitions are unavoidable. During a partition, systems must choose between returning possibly inconsistent data (availability) or rejecting requests (consistency). This trade-off directly impacts user experience and correctness.

---

## **4. Why is consensus required for leader election?**

**Answer:**
Without consensus, multiple nodes may believe they are leaders (split-brain). Consensus ensures that at most one leader is recognized by a majority, preserving safety.

---

## **5. Why do systems use quorums?**

**Answer:**
Quorums ensure overlapping majorities, which prevents conflicting decisions. If two operations require majority agreement, they cannot both succeed with different values.

---

## **6. What problems does eventual consistency introduce?**

**Answer:**

* stale reads
* conflicts
* divergent replicas
* application-level reconciliation

But it provides high availability and low latency.

---

## **7. When is causal consistency better than linearizability?**

**Answer:**
When user-perceived ordering matters but global ordering does not. It provides intuitive behavior with lower coordination cost, making it suitable for social networks and messaging systems.

---

## **8. Why canâ€™t we have exactly-once semantics easily?**

**Answer:**
Because failures make it impossible to know whether an operation succeeded. Retries can duplicate effects. Systems instead provide at-least-once delivery with idempotency.

---

## **9. Why is consensus not used everywhere?**

**Answer:**
Because it is expensive in terms of latency, throughput, and operational complexity. Systems isolate consensus to small, critical components.

---

## **10. How would you design a scalable system using Chapter 9 principles?**

**Answer:**

* Use eventual or causal consistency for high-volume data
* Use linearizability only for coordination metadata
* Isolate consensus to control planes
* Design idempotent operations
* Accept temporary inconsistency