## **Topic 6.3 — Partitioning and Secondary Indexes**

Partitioning works very well for **primary-key lookups** because the system can easily determine **which partition stores a given key**. But in most real applications, queries are not limited to primary keys. They often require access by **secondary attributes**, such as:

* email = "[john@example.com](mailto:john@example.com)"
* status = "active"
* age > 30
* category = "electronics" AND price < 100

Handling **secondary indexes** in a partitioned distributed system is dramatically more complex than in a single-node database.

This topic explains:

* how secondary indexes work in partitioned databases,
* how global vs local indexes differ,
* how queries are routed,
* and the trade-offs between consistency, performance, and operational complexity.

---

# **I. Why Secondary Indexes Are Hard in Partitioned Systems**

Imagine your data is partitioned by **user_id**:

```
Partition 1 → user_id 1–1M  
Partition 2 → user_id 1M–2M  
Partition 3 → user_id 2M–3M  
...
```

But now you query:

```
SELECT * FROM users WHERE email = 'abc@gmail.com';
```

The email field is **not correlated** with user_id.

Thus, **you don’t know which partition holds the row**.

This is the fundamental challenge:

> **Secondary indexes may require looking across multiple partitions**, which breaks the simple key-based routing.

Partitioned databases handle this using two models:

* **Local Secondary Indexes**
* **Global Secondary Indexes**

Both have trade-offs.

---

# **II. Local Secondary Indexes (LSI)**

A **local index** is stored *within the same partition* as the primary data.

### **How it works**

Each partition maintains its own secondary index for the records it stores.

Example:

* Partition 1 maintains an index on (email → user_id) for its subset.
* Partition 2 maintains its own.
* Partition 3 maintains its own.

### **Characteristics**

✔ Fast lookups within partition
✔ No network hops for index maintenance
✔ Easy to maintain consistency (local writes)

But:

### **Disadvantages**

❌ Querying a secondary index requires **scatter/gather**
→ query all partitions
→ merge results
→ high latency
→ expensive for large clusters

❌ Cannot enforce global uniqueness
e.g., ensuring email is unique globally is very difficult with only local indexes

### **Used in**

* Cassandra Local Indexes
* HBase locality groups
* Sharded MySQL (unless using global indexes manually)

Local indexes are simple and efficient *per partition*, but inefficient *cluster-wide*.

---

# **III. Global Secondary Indexes (GSI)**

A **global index** is stored in a separate, partitioned structure that covers all data across all shards.

### **How it works**

You create an index on a secondary attribute:

```
CREATE INDEX users_by_email ON users(email);
```

The index structure itself is **cross-partition** and stored in its own partitions.

So instead of keeping the email index inside each user partition, you make something like:

```
Index Partition A → emails hashed 0–127
Index Partition B → emails hashed 128–255
...
```

When querying:

* email lookup goes to the **global index partition**,
* the index returns the primary key (user_id),
* client then queries the correct partition of the main table.

### **Advantages**

✔ Efficient point queries
✔ Avoids scatter/gather
✔ Supports global uniqueness constraints
✔ Supports fast access on non-primary attributes

### **Disadvantages**

❌ Much more complex to maintain
❌ Writes become more expensive
(must update both data partition + index partition)
❌ Requires distributed transactions or eventual consistency
❌ Index partitions may become hotspots (if attribute skewed)

### **Used in**

* Google Spanner (global indexes with transactions)
* CockroachDB (global indexes via MVCC + consistency)
* DynamoDB (GSI with eventual consistency)
* MongoDB 6.0+ (cluster-wide indexes)

---

# **IV. Write Path for Global Indexes**

When inserting or updating a document:

### **Write must update:**

1. **Primary partition** (based on primary key)
2. **Index partition** (based on secondary attribute)

Example:

```
INSERT INTO users (id=123, email="abc@gmail.com")
```

* Primary data → goes to partition hash(id)
* Secondary index entry → goes to partition hash(email)

This creates a **two-parted write**, requiring:

* distributed agreement
* atomic commit
* or carefully designed eventual consistency semantics.

---

# **V. Consistency Challenges for Global Indexes**

Because index and data live in **different partitions**, they can become inconsistent.

Example failure scenario:

* Data insert succeeds on primary partition.
* Index update fails due to network issue.
  → Now primary and index disagree.

Solutions:

### **1. Distributed Transactions**

* Use 2-phase commit (2PC)
* Ensures atomic writes to both partitions
* Expensive and slow

Used in:

* Spanner
* CockroachDB
* YugabyteDB

### **2. Asynchronous Index Maintenance**

* Write to primary
* Queue background task to update index
* Eventual consistency
* Might temporarily return stale results

Used in:

* DynamoDB GSI
* Some Elasticsearch pipelines

### **3. Log-based Indexing**

* Use change data capture (CDC)
* Update indexes asynchronously
* Guarantees monotonic ordering

Used in:

* Kafka-based indexing
* Elasticsearch ingest pipelines
* RocksDB-based embedded systems

Each solution trades off performance vs consistency.

---

# **VI. Partitioning Strategy for Indexes Themselves**

Indexes must also be partitioned.

Two common strategies:

### **1. Index Partitioned by Secondary Key**

```
index_partition = hash(secondary_key) → partition_id
```

Fast for point queries, but poor for range queries.

### **2. Range Partitioned Secondary Index**

```
secondary_key in [A–F] → index shard 1
secondary_key in [F–M] → index shard 2
...
```

Great for:

* prefix queries,
* range scans,
* text search.

Used in:

* Spanner (sorted global indexes)
* CockroachDB (ordered key-value store under the hood)

---

# **VII. Covering Indexes and Index-Only Queries**

In some systems, global secondary indexes store **extra fields** to avoid touching the primary table.

Example:

```
INDEX users_by_email (email) COVERING (age, status)
```

This allows:

```
SELECT age FROM users WHERE email="abc@gmail.com"
```

to be answered directly from index partitions **without fetching primary data**.

However:

* increases index size,
* increases write amplification,
* more replication,
* more cost.

---

# **VIII. Secondary Indexes in Leaderless Systems**

In Dynamo-style leaderless systems (Cassandra, Riak), GSIs are hard:

* R+W quorums create version divergence.
* Indexes across partitions can become inconsistent.
* No strict ordering → hard to guarantee correctness.

Cassandra local secondary indexes are:

* stored locally on each replica,
* not globally consistent,
* unsuitable for high-cardinality fields,
* inefficient for large partitions.

Better alternatives:

* Materialized views (Cassandra MV; but have correctness issues),
* Search engines like Solr/Elasticsearch for indexing,
* Application-managed indexes.

---

# **IX. Query Routing with Secondary Indexes**

### **Local indexes**

* coordinator must query all partitions
* latency = slowest partition

### **Global indexes**

* coordinator routes query to appropriate index partition
* retrieves primary key(s)
* fetches data from related partitions

Query involves:

* two hops (index lookup + data fetch)
* or one hop if covering index.

Global indexes improve performance dramatically **at the cost of higher write complexity**.

---

# **X. Writes Become More Expensive with Indexes**

Adding indexes changes write path from:

```
Write primary key
```

To:

```
Write primary key
Write secondary index 1
Write secondary index 2
...
```

In distributed systems, these writes may target **different partition leaders**, meaning:

* more network hops,
* more replication cascades,
* more chances for partial failure,
* more need for atomic commit mechanisms.

Indexes increase **write amplification**.

---

# **XI. Real-World Implementations**

### **Cassandra**

* Local secondary indexes
* Materialized views (eventually consistent)
* Limited use cases

### **MongoDB**

* Sharded clusters support **cluster-wide indexes** (newer versions)
* Uses background index building

### **DynamoDB**

* GSI with **eventual consistency**
* Async propagation from table to index

### **Spanner / CockroachDB**

* Global indexes with **true transactional consistency**
* Use distributed MVCC + two-phase commit

These implementations demonstrate two opposite ends of the design spectrum:

* extremely strong consistency (Spanner)
* extremely high availability (DynamoDB)
* practical middle ground (MongoDB, Elastic, Cassandra)

---

# **XII. Key Takeaways for Topic 6.3**

### **1. Secondary indexes are much harder in partitioned systems**

They require cross-partition coordination.

### **2. Local indexes are simple but require scatter/gather**

Good for simple workloads, bad for large clusters.

### **3. Global indexes solve this but make writes more expensive**

They require additional partition lookups and often some form of distributed transaction.

### **4. Consistency trade-offs vary by database**

* Spanner = strong consistency
* DynamoDB = eventual
* Cassandra = per-replica local only

### **5. Index partitioning itself must be designed carefully**

Choose hash vs range partitioning depending on query patterns.

### **6. Indexes increase write load significantly**

Every additional index means more cross-partition work.

### **7. Covering indexes can avoid table lookups**

But increase storage and replication costs.

### **8. Designing effective indexes in distributed systems requires deep understanding of workload patterns**

Especially:

* read vs write ratio,
* cardinality,
* access patterns,
* latency constraints.