## **Topic 4.6 — Dataflow Through Databases**

Dataflow through databases refers to how data moves between applications using a shared database as the communication mechanism. Instead of sending messages or calling APIs, multiple applications **read and write from the same database**, treating it as the integration point. This approach may seem simple, but it introduces subtle challenges related to coupling, schema evolution, performance, and consistency.

Historically, this was a common integration style in monolithic or enterprise environments. Today, it is still widely used—but modern distributed systems increasingly replace it with event-driven or service-based integration due to the risks of tight coupling.

---

### **How Shared Database Dataflow Works**

Example:

```
Service A (writes data)  →  Database  →  Service B (reads data)
```

Applications communicate *indirectly* by inserting, updating, or reading database records.

Common patterns:

* Application creates a record → another app polls for new rows
* Batch ETL reads from operational DB → populates analytics DB
* Shared tables used across services for reporting, scheduling, auditing

The database becomes both:

* The **system of record**, and
* The **integration channel**

---

### **Advantages of Shared Database Integration**

| Benefit                     | Explanation                                                      |
| --------------------------- | ---------------------------------------------------------------- |
| Simple integration pattern  | No messaging system or RPC needed                                |
| Guaranteed consistency      | Since both parties read/write the same data store                |
| Easy historical access      | All consumers see the same data source                           |
| Useful for legacy monoliths | When a system was not originally designed for network boundaries |

This model is easy to adopt early in system evolution.

---

### **Major Problems and Risks**

As systems scale, shared databases introduce several issues:

#### **1. Tight Coupling**

Multiple applications depend directly on the database schema. A change in schema may break many consumers.

Example: Renaming a column → multiple applications fail unless coordinated updates occur.

#### **2. unclear ownership**

Who owns a table or field? With many writers, enforcing invariants is difficult.

#### **3. Lack of Access Control Boundaries**

Applications may infer meaning from fields never intended for external use.

#### **4. Difficult Schema Evolution**

Database schema must evolve carefully because:

* Old readers expect old structure
* New writers expect new structure

Migration often becomes slow and risky.

#### **5. Performance Interference**

One application’s heavy load (batch job, analytics, or scan) can degrade performance of others.

---

### **Workload Separation: OLTP vs OLAP**

Shared databases often combine:

* **Operational, transactional workloads (OLTP)**
  e.g., reading/writing orders, managing user accounts
* **Analytical workloads (OLAP)**
  e.g., reporting, dashboards, machine learning pipelines

This leads to issues:

| Problem             | Example                                          |
| ------------------- | ------------------------------------------------ |
| Lock contention     | Reports trigger full-table scans blocking writes |
| Slow queries        | Analytics engine overwhelms transactional RDBMS  |
| Resource contention | Indexes optimized for reporting degrade inserts  |

Modern systems address this by separating concerns.

---

### **Typical Modern Pattern: Dual Databases**

Instead of shared access to the same database:

```
Operational DB --> ETL or CDC --> Analytical DB
```

Data is extracted or streamed rather than shared directly.

Techniques include:

* ETL pipelines (batch copying)
* Change Data Capture (CDC)
* Event streaming (Kafka)
* Replication into columnar or warehouse stores

This enables:

* Operational system optimized for transactions
* Analytical system optimized for queries

---

### **Change Data Capture (CDC) and Dataflow**

CDC tools sit between database and downstream systems, detecting changes and publishing them (often as events).

Examples:

* Debezium
* AWS DMS
* SQL Server CDC
* Oracle GoldenGate

CDC is a stepping stone from shared DB architecture to event-driven architecture.

---

### **Anti-pattern: Using the Database as a Messaging System**

Some systems simulate messaging by storing pending work in a table, then polling:

```sql
SELECT * FROM jobs WHERE status = 'pending';
```

Problems:

* High polling frequency → wasted load
* Locks and race conditions
* Poor latency and reliability pattern

Message queues or event logs are better suited.

---

### **Schema Evolution with Shared Databases**

When many components rely on the same schema, evolution must be:

* Incremental
* Backward compatible
* Carefully coordinated

Patterns include:

* Expand–migrate–contract approach
* Adding nullable fields instead of deleting columns
* Keeping compatibility layers (views, aliases)

---

### **Benefits of Database-as-Integration When Done Carefully**

Shared DBs can still be valuable for:

* Legacy monolithic systems with multiple internal modules
* Backup recovery patterns
* Read-only data sharing (e.g., replicated reporting DB)
* Embedded applications without messaging infrastructure

But **must avoid multi-service write access**.

---

### **Recommended Evolution Path**

Best practice is to treat shared DB usage as a **transition phase** toward clearer ownership:

| Stage | Approach                                                |
| ----- | ------------------------------------------------------- |
| 1     | Shared read/write database                              |
| 2     | Ownership boundaries established (one writer per table) |
| 3     | CDC used for integration                                |
| 4     | Event-driven or API-based dataflow                      |

Modern distributed systems increasingly adopt stages 3–4.

---

### **Key Principle**

Using a database as an integration mechanism is simple but introduces tight coupling, schema fragility, and performance risks as systems scale. While acceptable in small or legacy systems, modern architectures benefit from separating responsibilities and using messaging or service contracts instead of shared database access.
