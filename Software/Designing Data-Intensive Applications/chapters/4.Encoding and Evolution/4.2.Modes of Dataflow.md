## **Topic 4.2 — Modes of Dataflow**

Once data is encoded, the next important question is: **how does it flow between systems?**
Modern software systems rarely work in isolation — they interact via APIs, event streams, shared databases, or message brokers. How data flows determines consistency guarantees, coupling between systems, performance behavior, and failure modes.

There are **three primary modes of dataflow**:

1. **Dataflow via Databases (Shared Data Storage)**
2. **Dataflow via Services (Synchronous or Asynchronous RPC / APIs)**
3. **Dataflow via Messaging Systems (Asynchronous Event Streaming)**

Each mode represents a different architectural style with distinct trade-offs regarding loose coupling, schema evolution, performance, and system scalability.

---

## **1. Dataflow Through Databases (Shared Data Storage)**

In this model, multiple services or applications read and write from the **same database**. The database is the central source of truth.

Example scenario:

* Application A writes customer data.
* Application B reads and processes it later.

This approach was common in monolithic architectures.

### **Advantages**

* Simple integration — no network messaging required.
* No need for streaming or messaging infrastructure.
* Strong consistency if ACID guarantees exist.

### **Disadvantages**

* **Tight coupling**: schema changes affect all consumers.
* Harder evolution — consumers may break if schema changes unexpectedly.
* Possible unintended dependencies (services rely on internals, not contract).

Many architectures discourage shared mutable databases between independent services, especially in microservices design.

---

## **2. Dataflow Via Services**

Instead of sharing a database, data flows by **calling another service**. This can be:

* **Synchronous** (REST, gRPC, SOAP)
* **Asynchronous** (callback-based or event-driven RPC)

Here, the service boundary replaces the database boundary.

Example:

```
Client -> Service A -> Service B
```

### **Data Encoding Matters**

Depending on protocol:

* REST mostly uses **JSON**
* gRPC uses **Protobuf**
* SOAP uses **XML**

### **Coupling Characteristics**

Services that communicate synchronously require **availability coupling** — if B is down, A may also fail unless fallback logic exists.

### **Advantages**

* Clear ownership of data and logic.
* Loose storage-level coupling (each service can choose its DB).
* Easier schema evolution with versioned interfaces.

### **Disadvantages**

* Latency sensitivity.
* Cascading failures in synchronous call chains.
* Complex dependency graph in distributed systems.

---

## **3. Dataflow via Messaging (Event Streams & Queues)**

In messaging-based systems, applications communicate indirectly by sending messages via a broker.

Examples:

* Kafka
* RabbitMQ
* Pulsar
* AWS SNS/SQS

Producers write messages; consumers read them **asynchronously**. Messages may contain:

* Full data (payload)
* Delta/patch
* Reference to storage

This enables **event-driven architecture**.

### **Key Concepts**

| Concept     | Meaning                     |
| ----------- | --------------------------- |
| Producer    | Sends a message             |
| Consumer    | Receives and processes      |
| Topic/Queue | Routing mechanism           |
| Partition   | Sharding for scale          |
| Offset      | Message position for replay |

### **Advantages**

* Loose coupling — producers and consumers evolve independently.
* High scalability and reliability.
* Consumers can replay history for analytics, debugging, or recovery.

### **Disadvantages**

* Requires schema versioning discipline.
* Debugging and observability are harder.
* Processing guarantees vary (exactly-once, at least-once, etc.).

---

## **Comparing the Dataflow Models**

| Property             | Database Sharing      | Services (RPC)             | Messaging                          |
| -------------------- | --------------------- | -------------------------- | ---------------------------------- |
| Coupling             | Tight                 | Medium                     | Loose                              |
| Latency Model        | Pull-based            | Request-response           | Asynchronous                       |
| Evolution Complexity | High                  | Medium                     | Low (if schema discipline exists)  |
| Failure Behavior     | DB becomes bottleneck | Cascading failure possible | Decoupled & resilient              |
| Suitability          | Monoliths / legacy    | Microservices              | Event-driven / distributed systems |

Each model remains relevant — the right tool depends on communication patterns and system requirements.

---

## **Hybrid Models in Real Systems**

Most real-world distributed systems combine all three modes:

* **Database storage for persistence**
* **Service-based synchronous calls for real-time workflows**
* **Messaging for asynchronous processing, integration, replication, auditing**

Example: **an e-commerce system**

* Order service stores order record → database
* Payment service calls fraud-check service via RPC
* Order event published → Kafka → analytics + email service consumed later

This layered approach improves flexibility and resilience.

---

## **Key Design Considerations**

Designing dataflow involves evaluating:

| Question                                 | Consideration                     |
| ---------------------------------------- | --------------------------------- |
| How fast must the consumer see new data? | Real-time vs eventual consistency |
| Can communication be delayed?            | Batch vs streaming                |
| What failure modes are acceptable?       | Retries, idempotency, waiting     |
| How often does the schema evolve?        | Versioning discipline required    |
| Who owns the data long-term?             | Contract boundaries               |

---

## **Key Principle**

Dataflow is not just about moving data — it defines **how systems interact, evolve, scale, and remain reliable over time**. Choosing the right mode impacts latency, coupling, throughput, operational complexity, and future maintainability.

The encoding format and the dataflow model together define the communication contract between components in a system. Excellent distributed design comes from understanding both dimensions, not just one.